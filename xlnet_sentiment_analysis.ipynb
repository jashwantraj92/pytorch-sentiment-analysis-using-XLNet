{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "XLNET_amazon-Copy1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5VACD4poXAr",
        "colab_type": "text"
      },
      "source": [
        " # ***Sentiment Analysis using XLNET in Pytorch***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIU5IR3PoXBG",
        "colab_type": "text"
      },
      "source": [
        "- **XLNet** is a state-of-the-art neural network designed for various NLP tasks.\n",
        "- Researchers from  Carnegie Mellon University and Google released a new pre-trained language     model called XLNet\n",
        "- The previous state-of-the-art language model is BERT, which achieves a GLUE (General Language Understanding Evaluation) score of 80.5%. GLUE is a benchmark for training, evaluating, and analyzing natural language understanding systems, and the human baseline score is 87.1%. \n",
        "- XLNet outperforms BERT on 20 tasks (many times by a large margin) and pushes the GLUE score to 88.4% which is greater than Humans!!!!! For detailed information read paper [XLNet paper](https://arxiv.org/abs/1906.08237)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfJqqN1OoXBg",
        "colab_type": "text"
      },
      "source": [
        "#### XLNet is pre-trained and made open source by google \n",
        "- The AIM of this article is to use the pytorch implementation of XLNet by huggingface [GitHub Repo](https://github.com/huggingface/transformers)\n",
        "    - **We will focus more on code in this article.** To understand XLNet and how it works read paper\n",
        "- We will perform a Binary Sentiment analysis on Amazon review dataset [Dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/00331/)\n",
        "- Install pytorch transformers with the following command \n",
        "<br> <code>pip install pytorch-transformers</code>\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3pHS_GfoXBv",
        "colab_type": "text"
      },
      "source": [
        "#### If you are on Google Colab then run\n",
        "<code> !pip install pytorch-transformers</code>\n",
        "#### In the notebook\n",
        "- You can upload the dataset on google drive and access in colab by using\n",
        "     - <code>from google.colab import drive <br> drive.mount('/content/drive') "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xeb1MHq-oXCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch-transformers # For Colab \n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PATH = \"--Path to Folder -- /amazon_cells_labelled.txt\"\n",
        "fd = pd.read_csv(PATH,sep='\\t')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lciQlQ6w9-Og",
        "outputId": "95085350-695e-4fc9-c1a5-e284c99a85d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "fd.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>So there is no way for me to plug it in here in the US unless I go by a converter.</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I have to jiggle the plug to get it to line up...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  So there is no way for me to plug it in here in the US unless I go by a converter.  0\n",
              "0                        Good case, Excellent value.                                  1\n",
              "1                             Great for the jawbone.                                  1\n",
              "2  Tied to charger for conversations lasting more...                                  0\n",
              "3                                  The mic is great.                                  1\n",
              "4  I have to jiggle the plug to get it to line up...                                  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6s0OEaHoXDi",
        "colab_type": "text"
      },
      "source": [
        "#### As you can see our dataset contains sentences with their value 1 for positive and 0 for negative\n",
        "We rename our columns as 'sentence' and 'value' "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nHBN5vXc-AEx",
        "colab": {}
      },
      "source": [
        "fd.columns = ['sentence','value']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J2BADEhO-Q5n",
        "outputId": "a9e6359b-7b5e-493b-a697-350d62367a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "fd.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I have to jiggle the plug to get it to line up...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  value\n",
              "0                        Good case, Excellent value.      1\n",
              "1                             Great for the jawbone.      1\n",
              "2  Tied to charger for conversations lasting more...      0\n",
              "3                                  The mic is great.      1\n",
              "4  I have to jiggle the plug to get it to line up...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI3TM-V7oXEu",
        "colab_type": "text"
      },
      "source": [
        "- XLNet need <code>[SEP] [CLS]</code> tags at the end of each sentence  \n",
        "- We add them by using following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RE440k7s-cEz",
        "colab": {}
      },
      "source": [
        "sentences  = []\n",
        "for sentence in fd['sentence']:\n",
        "  sentence = sentence+\"[SEP] [CLS]\"\n",
        "  sentences.append(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NP1e3cNs-g3v",
        "outputId": "c51aa8b1-78c6-42a2-b36a-2853f9d5668c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentences[0] ##To check if tags are added or not"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Good case, Excellent value.[SEP] [CLS]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_qt4RLQoXF4",
        "colab_type": "text"
      },
      "source": [
        "#### *We import all the dependencies* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5dWrSbI5_WTI",
        "colab": {}
      },
      "source": [
        "from pytorch_transformers import XLNetTokenizer,XLNetForSequenceClassification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hmwkinAm_1m-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "3dd94977-5afc-4630-dba9-3c0439e9642d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_transformers import AdamW\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfPGi_EIoXHY",
        "colab_type": "text"
      },
      "source": [
        "### Inputs\n",
        "\n",
        "1. XLNet tokenizer is used to convert our text into tokens that correspond to   XLNet’s vocabulary.\n",
        "2. a sequence of integers identifying each input token to its index number in the XLNet tokenizer \n",
        "    - Use the XLNet tokenizer to convert the tokens to their index numbers in the XLNet vocabulary\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lwqJ212uAtck",
        "colab": {}
      },
      "source": [
        "tokenizer  = XLNetTokenizer.from_pretrained('xlnet-base-cased',do_lower_case=True)\n",
        "tokenized_text = [tokenizer.tokenize(sent) for sent in sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y4O23uMZBN6K",
        "outputId": "b28dc371-defc-4581-dc7a-8522dba79b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "tokenized_text[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁good',\n",
              " '▁case',\n",
              " ',',\n",
              " '▁excellent',\n",
              " '▁value',\n",
              " '.',\n",
              " '[',\n",
              " 's',\n",
              " 'ep',\n",
              " ']',\n",
              " '▁[',\n",
              " 'cl',\n",
              " 's',\n",
              " ']']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ie341hRDB6T4",
        "colab": {}
      },
      "source": [
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OK-UXNt5CeTN",
        "outputId": "cfea254a-d08d-4188-cea4-d09b01055282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(input_ids[0])\n",
        "labels = fd['value'].values\n",
        "print(labels[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[195, 363, 19, 2712, 991, 9, 10849, 23, 3882, 3158, 4145, 11974, 23, 3158]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONrApxqmoXJN",
        "colab_type": "text"
      },
      "source": [
        "### We find the maximum length of our sentences so that we can pad the rest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MYx9P-pZFrU6",
        "outputId": "56c7aa88-173c-42cd-f86c-b621c6b75385",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max1 = len(input_ids[0])\n",
        "for i in input_ids:\n",
        "  if(len(i)>max1):\n",
        "    max1=len(i)\n",
        "print(max1)\n",
        "MAX_LEN = max1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5211mavoXJt",
        "colab_type": "text"
      },
      "source": [
        "#### We pad our sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sz7Y0D3xGKaw",
        "colab": {}
      },
      "source": [
        "input_ids2 = pad_sequences(input_ids,maxlen=MAX_LEN,dtype=\"long\",truncating=\"post\",padding=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A8KPBEzPCgo9",
        "colab": {}
      },
      "source": [
        "xtrain,xtest,ytrain,ytest = train_test_split(input_ids2,labels,test_size=0.15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AlbOgQ-_DAyv",
        "outputId": "101fcc16-0c2c-4bbf-9bb9-58e8076779a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(input_ids2[0]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YSjgfMLxDCyi",
        "colab": {}
      },
      "source": [
        "Xtrain = torch.tensor(xtrain)\n",
        "Ytrain = torch.tensor(ytrain)\n",
        "Xtest = torch.tensor(xtest)\n",
        "Ytest = torch.tensor(ytest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dj1ef2DNFHLc",
        "colab": {}
      },
      "source": [
        "batch_size = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hrTbjxhhHsDc",
        "colab": {}
      },
      "source": [
        "train_data = TensorDataset(Xtrain,Ytrain)\n",
        "test_data = TensorDataset(Xtest,Ytest)\n",
        "loader = DataLoader(train_data,batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data,batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9-ELFF0PIr81",
        "outputId": "bcb5db9c-50b1-423c-817a-fa699d3c7ce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\",num_labels=2)\n",
        "model.cuda()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForSequenceClassification(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (6): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (7): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (8): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (9): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (10): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (11): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (sequence_summary): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "    (first_dropout): Identity()\n",
              "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (logits_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_HVeV0eoXOI",
        "colab_type": "text"
      },
      "source": [
        "- We use AdamW optimizer which is imported earlier\n",
        "- For loss function we use Cross Entropy Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wKPtP7zaLShu",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),lr=2e-5)# We pass model parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LXEydZNIm4-J",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nZL4HkhCLcff",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def flat_accuracy(preds,labels):  # A function to predict Accuracy\n",
        "  correct=0\n",
        "  for i in range(0,len(labels)):\n",
        "    if(preds[i]==labels[i]):\n",
        "      correct+=1\n",
        "  return (correct/len(labels))*100\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIaGghHQoXPN",
        "colab_type": "text"
      },
      "source": [
        "### Here our training Begins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tfr3IOEoSymH",
        "outputId": "8158327b-1eed-4679-a93b-000b3812ef77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "no_train = 0\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  loss1 = []\n",
        "  steps = 0\n",
        "  train_loss = []\n",
        "  l = []\n",
        "  for inputs,labels1 in loader :\n",
        "    inputs.to(device)\n",
        "    labels1.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs.to(device))\n",
        "    loss = criterion(outputs[0],labels1.to(device)).to(device)\n",
        "    logits = outputs[1]\n",
        "    #ll=outp(loss)\n",
        "    [train_loss.append(p.item()) for p in torch.argmax(outputs[0],axis=1).flatten() ]#our predicted \n",
        "    [l.append(z.item()) for z in labels1]# real labels\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss1.append(loss.item())\n",
        "    no_train += inputs.size(0)\n",
        "    steps += 1\n",
        "  print(\"Current Loss is : {} Step is : {} number of Example : {} Accuracy : {}\".format(loss.item(),epoch,no_train,flat_accuracy(train_loss,l)))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Loss is : 0.057762544602155685 Step is : 0 number of Example : 849 Accuracy : 68.31566548881037\n",
            "Current Loss is : 0.006311813835054636 Step is : 1 number of Example : 1698 Accuracy : 93.05064782096584\n",
            "Current Loss is : 0.00749961519613862 Step is : 2 number of Example : 2547 Accuracy : 92.8150765606596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbM73sOCoXPl",
        "colab_type": "text"
      },
      "source": [
        "- torch.argmax() returns the index of the max number \n",
        "- axis = 1 means that it will search maximum number in a row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d_aXqH0dhKKA",
        "outputId": "89d620b4-2be5-4bd0-f575-d2c56cffb695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.eval()#Testing our Model\n",
        "acc = []\n",
        "lab = []\n",
        "t = 0\n",
        "for inp,lab1 in test_loader:\n",
        "  inp.to(device)\n",
        "  lab1.to(device)\n",
        "  t+=lab1.size(0)\n",
        "  outp1 = model(inp.to(device))\n",
        "  [acc.append(p1.item()) for p1 in torch.argmax(outp1[0],axis=1).flatten() ]\n",
        "  [lab.append(z1.item()) for z1 in lab1]\n",
        "print(\"Total Examples : {} Accuracy {}\".format(t,flat_accuracy(acc,lab)))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Examples : 150 Accuracy 93.33333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}